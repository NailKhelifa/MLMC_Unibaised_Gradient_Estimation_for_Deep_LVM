{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">  **SIMULATIONS ET MÉTHODES DE MONTE CARLO**  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from scipy.stats import multivariate_normal\n",
    "import Estimateurs\n",
    "import Code\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">  **NOTATIONS**  </span> : on se donne un ensemble de données $\\boldsymbol{x} = \\{x^{(i)}\\}_{i=1}^n$ composé de $n$ échantillons i.i.d. d'une variable continue ou discrète $x$ à valeurs dans un espace d'observations $\\boldsymbol{\\mathcal{X}}$ (ainsi $\\boldsymbol{x} \\in \\boldsymbol{\\mathcal{X}}$). Nous supposons que les données sont générées par un processus aléatoire impliquant une variable aléatoire continue non observée $\\boldsymbol{z} = \\{z^{(i)}\\}_{i=1}^n$ à valeur dans un espace d'observations $\\boldsymbol{\\mathcal{Z}}$ (ainsi $\\boldsymbol{z} \\in \\boldsymbol{\\mathcal{Z}}$). Le processus se compose de deux étapes :\n",
    "\n",
    "\n",
    "1. La valeur $z^{(i)}$ est générée à partir d'une distribution a priori $p_{\\theta^*}(z)$ ;\n",
    "2. Une valeur $x^{(i)}$ est générée à partir d'une distribution conditionnelle $p_{\\theta^*}(x|z)$.\n",
    "\n",
    "\n",
    "Nous supposons que la distribution a priori $p_{\\theta^*}(\\boldsymbol{z})$ et la vraisemblance $p_{\\theta^*}(\\boldsymbol{x}|\\boldsymbol{z})$ proviennent de familles paramétriques de distributions $p_{\\theta}(\\boldsymbol{z})$ et $p_{\\theta}(\\boldsymbol{x}|\\boldsymbol{z})$ et on note $\\Theta \\subset \\mathbb{R}^d$ l'espace des paramètres. On connait ainsi l'expression de ces deux distributions. En revanche une grande partie de ce processus nous est cachée : les véritables paramètres $\\theta^*$ ainsi que les valeurs des $\\textbf{variables latentes}$ $z^{(i)}$ nous sont inconnus. \n",
    "\n",
    "Connaissant l'expression de la distribution a priori $p_{\\theta^*}(\\boldsymbol{z})$ et la vraisemblance $p_{\\theta^*}(\\boldsymbol{x}|\\boldsymbol{z})$ pour tout $\\theta \\in \\Theta$, on peut définir la densité jointe $p_{\\theta}(\\boldsymbol{x}, \\boldsymbol{z})$ sur $\\boldsymbol{\\mathcal{X}} \\times \\boldsymbol{\\mathcal{Z}}$ par : \n",
    "\n",
    "$$\n",
    "p_{\\theta}(\\boldsymbol{x}, \\boldsymbol{z}) = p_{\\theta}(\\boldsymbol{x}|\\boldsymbol{z}) p_{\\theta}(\\boldsymbol{z})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">  **OBJECTIF**  </span> : on cherche à déterminer la vraie valeur du paramètre (ici $\\theta^*$) ainsi que les valeurs des variables latentes. \n",
    "\n",
    "Une approche classique pour apprendre $\\boldsymbol{\\theta}$ est de choisir, si celle-ci existe, la valeur de ce paramètre qui maximise la log-vraisemblance marginale de l’ ́echantillon définie par :\n",
    "\n",
    "$$\n",
    "\\ell(\\boldsymbol{\\theta}) = \\log p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}) = \\log \\int_{\\boldsymbol{\\mathcal{Z}}} p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}, \\boldsymbol{z}) d\\boldsymbol{z}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">  **PROBLÈME**  </span> : l'intégrale donnée en ci-dessus est intractable (nous ne pouvons donc pas évaluer ou différencier la vraisemblance marginale)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">  **SOLUTION**  </span> : dans le but de résoudre les problèmes ci-dessus, introduisons un **modèle de reconnaissance** (paramétrique) {$ q_{\\phi}(\\boldsymbol{z}|\\boldsymbol{x}) : \\phi \\in \\Phi$} avec $\\Phi \\subset \\mathbb{R}^d$. Pour tout $\\phi$, $q_{\\phi}(\\boldsymbol{z}|\\boldsymbol{x})$ est choisi comme une approximation de la véritable postérieure intractable $p_{\\theta}(\\boldsymbol{z}|\\boldsymbol{x})$. L'idée est donc de proposer une valeur de l'a posteriori (faire une hypothèse) et d'introduire une méthode pour apprendre les paramètres du **modèle de reconnaissance** $\\phi$ conjointement avec les paramètres du **modèle génératif** $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\">  **Partie 0. Définition du cadre gaussien pour la génération des données**  </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Application numérique inspirée de [Rainforth et al. (2018)](https://arxiv.org/pdf/1802.04537.pdf))\n",
    "\n",
    "- Le **modèle génératif** est donné par $p_{\\theta}(\\boldsymbol{x}, \\boldsymbol{z}) = \\mathcal{N}(\\boldsymbol{z}|\\theta, I) \\mathcal{N}(\\boldsymbol{x}|\\boldsymbol{z}, I)$, où $\\boldsymbol{x}$ et $\\boldsymbol{z} \\in \\mathbb{R}^{20}$, de sorte que $p_{\\theta}(\\boldsymbol{x}) = \\mathcal{N}(\\boldsymbol{x}|\\theta, 2I)$ et $p_{\\theta}(\\boldsymbol{z}|\\boldsymbol{x}) = \\mathcal{N}\\left( \\frac{\\theta + x}{2}, \\frac{1}{2}I \\right)$. \n",
    "\n",
    "- La **distribution de l'encodeur** (le modèle de reconnaissance) est $q_{\\phi}(z|x) = \\mathcal{N}\\left(\\boldsymbol{z}|A\\boldsymbol{x} + b, \\frac{2}{3}I \\right)$, où $\\phi = (A, b)$.\n",
    "\n",
    "- Nous considérons des perturbations aléatoires des paramètres près de la valeur optimale par une distribution gaussienne de moyenne nulle et d'écart-type $0.01$.\n",
    "\n",
    "**Dans ce cas, on peut analytiquement calculer la vraie log-vraisemblance du modèle pour quantifier le biais et la variance de tous les estimateurs**.\n",
    "\n",
    "Puisque $q_{\\phi}(z|x) = \\mathcal{N}\\left(\\boldsymbol{z}|A\\boldsymbol{x} + b, \\frac{2}{3}I \\right)$ est censé être une approximation de la véritable loi a posteriori donnée par $p_{\\boldsymbol{\\theta}}(\\boldsymbol{z} | \\boldsymbol{x}) = \\mathcal{N}\\left( \\frac{\\theta + x}{2}, \\frac{1}{2}I \\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par tirer le $\\theta$* ($\\in \\mathbb{R}$) qui sera le paramètre que l'on cherchera à estimer par la suite. \n",
    "\n",
    "A la manière de la génération des données dans [Rainforth et al. (2018)](https://arxiv.org/pdf/1802.04537.pdf) : $\\theta^* \\sim \\mathcal{N}(0, 1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La valeur de theta à estimer est -0.88\n"
     ]
    }
   ],
   "source": [
    "#theta_true = np.random.multivariate_normal(np.zeros(20), np.identity(20))\n",
    "theta_true = np.random.normal(0, 1)\n",
    "print(f\"La valeur de theta à estimer est {int(theta_true*100)/100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'idée est désormais de tirer une observation $\\boldsymbol{x} \\in \\mathbb{R}^{20}$, chose que l'on peut faire puisque toutes les distributions nous sont données. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'échantillon x observé est :\n",
      " \n",
      " x = [-0.43548093 -2.84157657 -0.92839158 -0.50877176  1.59179437 -1.12581122\n",
      " -1.1247385  -0.58555786  1.04584073  1.58379139  0.72044592 -0.86696259\n",
      " -0.1819326   1.5291075   0.85032961  0.60834023 -1.85762531 -2.74547288\n",
      " -0.48179404  0.99914896] \n",
      " \n",
      " et on vérifique bien sa taille est celle voulue : (20,)\n"
     ]
    }
   ],
   "source": [
    "## On se donne notre échantillon x\n",
    "\n",
    "x, _ = Estimateurs.joint_probability(theta_true)\n",
    "\n",
    "print(f\"L'échantillon x observé est :\\n \\n x = {x} \\n \\n et on vérifique bien sa taille est celle voulue : {x.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est maintenant question de tirer notre encodeur tel que : $q_{\\phi}(z|x) = \\mathcal{N}\\left(\\boldsymbol{z}|A\\boldsymbol{x} + b, \\frac{2}{3}I \\right)$, où $\\phi = (A, b)$. **Le problème qui se pose est donc celui du choix de $A$ et de $b$**. Dans l'article [Rainforth et al. (2018)](https://arxiv.org/pdf/1802.04537.pdf), il nous est indiqué : \n",
    "\n",
    "*\"Following [Rainforth et al. (2018)](https://arxiv.org/pdf/1802.04537.pdf), we consider random perturbations of the parameters near the optimal value by a zero-mean Gaussian with standard deviation 0.01\"*\n",
    "\n",
    "Ainsi, étant donné une observation $\\boldsymbol{x}$,  le choix parfait pour $\\phi$ serait $\\phi^* = (A^*, b^*)$ où $A^* = \\frac{1}{2}\\boldsymbol{I}_{20} \\in \\mathbb{R}^{20 \\times 20}$ et $b^* = [\\frac{\\theta^*}{2}, ..., \\frac{\\theta^*}{2}]^T \\in \\mathbb{R}^{20} $. Suivant l'indication dans l'article, nous nous plaçons dans un cas où on aurait réussi à inférer de manière convenable la loi $p_{\\theta}(\\boldsymbol{z}|\\boldsymbol{x}) = \\mathcal{N}\\left( \\frac{\\theta + x}{2}, \\frac{1}{2}I \\right)$, mais pas parfaitement. Ainsi,  on introduit de la même façon que dans l'article [[Rainforth et al. (2018)](https://arxiv.org/pdf/1802.04537.pdf) une perturbation autour de la valeur optimale du paramètre $\\phi$. Cette perturbation se caractérise par le fait chaque dimension de chaque paramètre a été décalée de manière aléatoire par rapport à sa valeur optimale en utilisant une gaussienne centrée en zéro avec un écart-type de 0,01.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On vérifie que les tailles de A, b et x coincident :\n",
      " \n",
      " taille A : (20, 20) \n",
      " taille b : (20,) \n",
      " taille x : (20,)\n"
     ]
    }
   ],
   "source": [
    "dim = 20 \n",
    "\n",
    "## On calcule les valeurs optimales de A et de b\n",
    "A = 0.5 * np.eye(dim)\n",
    "b = 0.5 * theta_true * np.ones(dim)\n",
    "\n",
    "## On calcule les valeurs perturbées de A et de b, qui sont FIXÉES dans la suite\n",
    "noised_A, noised_b = Code.noised_params(A, b)\n",
    "\n",
    "print(f\"On vérifie que les tailles de A, b et x coincident :\\n \\n taille A : {A.shape} \\n taille b : {b.shape} \\n taille x : {x.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/site-packages (4.66.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/khelifanail/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/q2/wg5gyfhj2r9cd97zfmckktvw0000gn/T/ipykernel_84822/1768422028.py\", line 4, in <module>\n",
      "    estimator = Code.log_likelihood_SUMO(r, theta_true, x, noised_A, noised_b, n_simulations)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/khelifanail/MLMC_Unibaised_Gradient_Estimation_for_Deep_LVM/Code.py\", line 164, in log_likelihood_SUMO\n",
      "TypeError: roulette_russe() missing 1 required positional argument: 'K'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/khelifanail/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/khelifanail/Library/Python/3.11/lib/python/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/khelifanail/Library/Python/3.11/lib/python/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/khelifanail/Library/Python/3.11/lib/python/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/khelifanail/Library/Python/3.11/lib/python/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/khelifanail/Library/Python/3.11/lib/python/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/khelifanail/Library/Python/3.11/lib/python/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/khelifanail/Library/Python/3.11/lib/python/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Users/khelifanail/Library/Python/3.11/lib/python/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/khelifanail/Library/Python/3.11/lib/python/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Users/khelifanail/Library/Python/3.11/lib/python/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/khelifanail/Library/Python/3.11/lib/python/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Users/khelifanail/Library/Python/3.11/lib/python/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"/Users/khelifanail/Library/Python/3.11/lib/python/site-packages/executing/executing.py\", line 190, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "r = 0.6\n",
    "n_simulations = 10\n",
    "\n",
    "estimator = Code.log_likelihood_SUMO(r, theta_true, x, noised_A, noised_b, n_simulations)\n",
    "estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
