{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from scipy.stats import multivariate_normal\n",
    "import Estimateurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par tirer le $\\theta$* ($\\in \\mathbb{R}$) qui sera le paramètre que l'on cherchera à estimer par la suite. \n",
    "\n",
    "A la manière de la génération des données dans l'article Rainforth et al. (2018) : $\\theta^* \\sim \\mathcal{N}(0, 1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La valeur de theta à estimer est 0.08\n"
     ]
    }
   ],
   "source": [
    "#theta_true = np.random.multivariate_normal(np.zeros(20), np.identity(20))\n",
    "theta_true = np.random.normal(0, 1)\n",
    "print(f\"La valeur de theta à estimer est {int(theta_true*100)/100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Désormais, on va tirer un échantillon $((Z_i, X_i))_i \\stackrel{iid}{\\sim} \\mathcal{N}(\\boldsymbol{z}|\\theta, \\boldsymbol{I}) * \\mathcal{N}(\\boldsymbol{x}|\\boldsymbol{z}, \\boldsymbol{I})$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'échantillon x observé est :\n",
      " \n",
      " x = [ 0.20694761 -1.77741858  0.49300505 -0.16893673  1.38833637 -1.55210182\n",
      "  0.6437169  -0.71711827 -0.56588384  3.20037538 -0.49377527 -0.47837875\n",
      " -1.72244462  0.9706274   0.69369104 -0.88425392  2.31302701  2.41096425\n",
      " -0.1924812   1.12517248] \n",
      " \n",
      " et sa taille est (20,)\n"
     ]
    }
   ],
   "source": [
    "## On se donne notre échantillon x\n",
    "\n",
    "x, _ = Estimateurs.joint_probability(theta_true)\n",
    "\n",
    "print(f\"L'échantillon x observé est :\\n \\n x = {x} \\n \\n et sa taille est {x.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ceci nous suffit pour tester notre classe Estimateurs dont le code se trouve dans le fichier Estimateurs.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_hat = np.mean(x)\n",
    "A, b = Estimateurs.noised_params((1/2)*np.eye(20), (np.zeros(20) + theta_true)/2)\n",
    "A_hat, b_hat = Estimateurs.noised_params((1/2)*np.eye(20), (np.zeros(20) + theta_hat)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_sample = Estimateurs.generate_encoder(x, 4, A, b)[0].T\n",
    "\n",
    "def compute_ratio(x, z, theta, A, b):\n",
    "    # Parameters\n",
    "    I = np.eye(20)\n",
    "\n",
    "    # Probability densities\n",
    "    p_theta_xz = np.exp(-0.5 * np.dot(np.dot((z - theta).T, np.linalg.inv(2*I)), (z - theta)) - 0.5 * np.dot(np.dot((x - z).T, np.linalg.inv(I)), (x - z)))\n",
    "    q_phi_z_given_x_density = np.exp(-0.5 * np.dot(np.dot((z - (np.dot(A, x) + b)).T, np.linalg.inv((2/3)*I)), (z - (np.dot(A, x) + b.flatten()))))\n",
    "\n",
    "    # Compute the ratio\n",
    "    ratio = p_theta_xz / q_phi_z_given_x_density\n",
    "\n",
    "    return ratio\n",
    "\n",
    "def weight(x, theta_hat, theta, A_hat, b_hat, A, b, z):\n",
    "\n",
    "    \n",
    "    ## calcul des poids pour theta_hat (associé à l'observation x)\n",
    "    weight_theta_hat = compute_ratio(x, z, theta_hat, A_hat, b_hat)\n",
    "\n",
    "    ## cacul des poids pour theta (associé à un theta)                                                                                                    \n",
    "    weight_theta = compute_ratio(x, z, theta, A, b)\n",
    "    \n",
    "    return (weight_theta_hat, weight_theta) ## attention, renvoie un tuple\n",
    "              \n",
    "def l_hat(x, theta_hat, theta, A_hat, b_hat, A, b, z_sample): \n",
    "\n",
    "\n",
    "    ## calcul de l_theta_hat (pour theta_hat)\n",
    "    l_theta_hat = np.log((1/(len(z_sample)) * sum(weight(x, theta_hat, theta, A_hat, b_hat, A, b, z_sample[i])[0] for i in range(len(z_sample)))))\n",
    "\n",
    "    ## calcul de l_theta (pour theta)\n",
    "    l_theta = np.log((1/(len(z_sample)) * sum(weight(x, theta_hat, theta, A_hat, b_hat, A, b, z_sample[i])[1] for i in range(len(z_sample)))))\n",
    "\n",
    "    return (l_theta_hat, l_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 20)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_sample[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2.832348085865691, -2.785726472660624)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_hat(z_sample[0], theta_hat, theta_true, A_hat, b_hat, A, b, z_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimateur = Estimateurs.Estimateurs(x, theta_true, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (4,) and (20,20) not aligned: 4 (dim 0) != 20 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/khelifanail/MLMC_Unibaised_Gradient_Estimation_for_Deep_LVM/Test_code.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/khelifanail/MLMC_Unibaised_Gradient_Estimation_for_Deep_LVM/Test_code.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m estimateur\u001b[39m.\u001b[39;49mgrad_ML_RR(theta_star\u001b[39m=\u001b[39;49mtheta_true, n_simulations\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n",
      "File \u001b[0;32m~/MLMC_Unibaised_Gradient_Estimation_for_Deep_LVM/Estimateurs.py:360\u001b[0m, in \u001b[0;36mEstimateurs.grad_ML_RR\u001b[0;34m(self, theta_star, n_simulations)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[39mfor\u001b[39;00m theta_val \u001b[39min\u001b[39;00m theta_values:\n\u001b[1;32m    359\u001b[0m     estimateur \u001b[39m=\u001b[39m Estimateurs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx, theta_val, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mr)\n\u001b[0;32m--> 360\u001b[0m     ML_RR_values\u001b[39m.\u001b[39mappend(estimateur\u001b[39m.\u001b[39;49mlog_likelihood_ML_RR(n_simulations)[\u001b[39m1\u001b[39m])\n\u001b[1;32m    362\u001b[0m gradient_ML_RR \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mgradient(ML_RR_values, theta_values)\n\u001b[1;32m    364\u001b[0m \u001b[39mreturn\u001b[39;00m gradient_ML_RR\n",
      "File \u001b[0;32m~/MLMC_Unibaised_Gradient_Estimation_for_Deep_LVM/Estimateurs.py:290\u001b[0m, in \u001b[0;36mEstimateurs.log_likelihood_ML_RR\u001b[0;34m(self, n_simulations)\u001b[0m\n\u001b[1;32m    286\u001b[0m     I_0_theta \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39ml_hat(z)[\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m z \u001b[39min\u001b[39;00m z_sample_theta])\n\u001b[1;32m    288\u001b[0m     \u001b[39m## On clacule l'estimateur de la roulette russe associé à ce delta, c'est celui qui correspond à l'estimateur RR \u001b[39;00m\n\u001b[1;32m    289\u001b[0m     \u001b[39m## et on stocke le résultat dans la liste RR sur laquelle on moyennera en sortie \u001b[39;00m\n\u001b[0;32m--> 290\u001b[0m     RR_theta_hat\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroulette_russe(I_0_hat, Delta_hat, K))\n\u001b[1;32m    291\u001b[0m     RR_theta\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroulette_russe(I_0_theta, Delta_theta, K))\n\u001b[1;32m    293\u001b[0m \u001b[39mreturn\u001b[39;00m (np\u001b[39m.\u001b[39mmean(RR_theta_hat), np\u001b[39m.\u001b[39mmean(RR_theta))\n",
      "File \u001b[0;32m~/MLMC_Unibaised_Gradient_Estimation_for_Deep_LVM/Estimateurs.py:213\u001b[0m, in \u001b[0;36mEstimateurs.roulette_russe\u001b[0;34m(self, I_0, Delta, K)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mroulette_russe\u001b[39m(\u001b[39mself\u001b[39m, I_0, Delta, K):\n\u001b[1;32m    197\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m    ---------------------------------------------------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m    IDEA: compute the rr estimator under the conditions of theorem 1 and a geometric distribution of parameter r for the \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[39m    ---------------------------------------------------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m--> 213\u001b[0m     \u001b[39mreturn\u001b[39;00m I_0 \u001b[39m+\u001b[39m \u001b[39msum\u001b[39m([Delta(\u001b[39m0\u001b[39;49m)] \u001b[39m+\u001b[39m [Delta(k)\u001b[39m/\u001b[39m((\u001b[39m1\u001b[39m\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mr)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m(k\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,K \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)])\n",
      "File \u001b[0;32m~/MLMC_Unibaised_Gradient_Estimation_for_Deep_LVM/Estimateurs.py:281\u001b[0m, in \u001b[0;36mEstimateurs.log_likelihood_ML_RR.<locals>.<lambda>\u001b[0;34m(k)\u001b[0m\n\u001b[1;32m    277\u001b[0m z_sample_theta, z_sample_odd_theta, z_sample_even_theta \u001b[39m=\u001b[39m generate_encoder(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx, \u001b[39m2\u001b[39m\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m(K\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m), noised_A\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mA, noised_b\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb)\n\u001b[1;32m    280\u001b[0m \u001b[39m## on se donne un delta particulier, celui qui correspond par définition à la méthode RR\u001b[39;00m\n\u001b[0;32m--> 281\u001b[0m Delta_hat \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m k: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ml_hat(z_sample_hat[:\u001b[39m2\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m(k\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m])[\u001b[39m0\u001b[39m] \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39ml_hat(z_sample_odd_hat[:\u001b[39m2\u001b[39m\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m(k)\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m])[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39ml_hat(z_sample_even_hat[:\u001b[39m2\u001b[39m\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m(k)\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m])[\u001b[39m0\u001b[39m])\n\u001b[1;32m    282\u001b[0m Delta_theta \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m k: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39ml_hat(z_sample_theta[:\u001b[39m2\u001b[39m\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m(k\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m])[\u001b[39m1\u001b[39m] \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39ml_hat(z_sample_odd_theta[:\u001b[39m2\u001b[39m\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m(k)\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m])[\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39ml_hat(z_sample_even_theta[:\u001b[39m2\u001b[39m\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m(k)\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m])[\u001b[39m1\u001b[39m])\n\u001b[1;32m    285\u001b[0m I_0_hat \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39ml_hat(z)[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m z \u001b[39min\u001b[39;00m z_sample_hat])\n",
      "File \u001b[0;32m~/MLMC_Unibaised_Gradient_Estimation_for_Deep_LVM/Estimateurs.py:188\u001b[0m, in \u001b[0;36mEstimateurs.l_hat\u001b[0;34m(self, z_sample)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[39m\u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[39m---------------------------------------------------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[39mIDEA: compute the biaised estimate of the log-likelihood l_theta(x) that we will later use to build our estimators. \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[39m---------------------------------------------------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[39m## calcul de l_theta_hat (pour theta_hat)\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m l_theta_hat \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlog((\u001b[39m1\u001b[39m\u001b[39m/\u001b[39m(\u001b[39mlen\u001b[39m(z_sample)) \u001b[39m*\u001b[39m \u001b[39msum\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight(z_val)[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m z_val \u001b[39min\u001b[39;00m z_sample)))\n\u001b[1;32m    190\u001b[0m \u001b[39m## calcul de l_theta (pour theta)\u001b[39;00m\n\u001b[1;32m    191\u001b[0m l_theta \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlog((\u001b[39m1\u001b[39m\u001b[39m/\u001b[39m(\u001b[39mlen\u001b[39m(z_sample)) \u001b[39m*\u001b[39m \u001b[39msum\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight(z_val)[\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m z_val \u001b[39min\u001b[39;00m z_sample)))\n",
      "File \u001b[0;32m~/MLMC_Unibaised_Gradient_Estimation_for_Deep_LVM/Estimateurs.py:188\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[39m\u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[39m---------------------------------------------------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[39mIDEA: compute the biaised estimate of the log-likelihood l_theta(x) that we will later use to build our estimators. \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[39m---------------------------------------------------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[39m## calcul de l_theta_hat (pour theta_hat)\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m l_theta_hat \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlog((\u001b[39m1\u001b[39m\u001b[39m/\u001b[39m(\u001b[39mlen\u001b[39m(z_sample)) \u001b[39m*\u001b[39m \u001b[39msum\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight(z_val)[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m z_val \u001b[39min\u001b[39;00m z_sample)))\n\u001b[1;32m    190\u001b[0m \u001b[39m## calcul de l_theta (pour theta)\u001b[39;00m\n\u001b[1;32m    191\u001b[0m l_theta \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlog((\u001b[39m1\u001b[39m\u001b[39m/\u001b[39m(\u001b[39mlen\u001b[39m(z_sample)) \u001b[39m*\u001b[39m \u001b[39msum\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight(z_val)[\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m z_val \u001b[39min\u001b[39;00m z_sample)))\n",
      "File \u001b[0;32m~/MLMC_Unibaised_Gradient_Estimation_for_Deep_LVM/Estimateurs.py:154\u001b[0m, in \u001b[0;36mEstimateurs.weight\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39m\u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39m---------------------------------------------------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[39mIDEA: compute importance weights according to the formula w_i = w(z_i) = p_theta(x, z_i)/q_phi(z_i|x)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m \n\u001b[1;32m    151\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[39m## calcul des poids pour theta_hat (associé à l'observation x)\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m weight_theta_hat \u001b[39m=\u001b[39m compute_ratio(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx, z, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtheta_hat, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mA_hat, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mb_hat)\n\u001b[1;32m    156\u001b[0m \u001b[39m## cacul des poids pour theta (associé à un theta)                                                                                                    \u001b[39;00m\n\u001b[1;32m    157\u001b[0m weight_theta \u001b[39m=\u001b[39m compute_ratio(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx, z, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtheta, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mA, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb)\n",
      "File \u001b[0;32m~/MLMC_Unibaised_Gradient_Estimation_for_Deep_LVM/Estimateurs.py:88\u001b[0m, in \u001b[0;36mcompute_ratio\u001b[0;34m(x, z, theta, A, b)\u001b[0m\n\u001b[1;32m     85\u001b[0m I \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39meye(\u001b[39m20\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[39m# Probability densities\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m p_theta_xz \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexp(\u001b[39m-\u001b[39m\u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mdot(np\u001b[39m.\u001b[39;49mdot((z \u001b[39m-\u001b[39;49m theta)\u001b[39m.\u001b[39;49mT, np\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49minv(\u001b[39m2\u001b[39;49m\u001b[39m*\u001b[39;49mI)), (z \u001b[39m-\u001b[39m theta)) \u001b[39m-\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mdot(np\u001b[39m.\u001b[39mdot((x \u001b[39m-\u001b[39m z)\u001b[39m.\u001b[39mT, np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39minv(I)), (x \u001b[39m-\u001b[39m z)))\n\u001b[1;32m     89\u001b[0m q_phi_z_given_x_density \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexp(\u001b[39m-\u001b[39m\u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mdot(np\u001b[39m.\u001b[39mdot((z \u001b[39m-\u001b[39m (np\u001b[39m.\u001b[39mdot(A, x) \u001b[39m+\u001b[39m b))\u001b[39m.\u001b[39mT, np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39minv((\u001b[39m2\u001b[39m\u001b[39m/\u001b[39m\u001b[39m3\u001b[39m)\u001b[39m*\u001b[39mI)), (z \u001b[39m-\u001b[39m (np\u001b[39m.\u001b[39mdot(A, x) \u001b[39m+\u001b[39m b\u001b[39m.\u001b[39mflatten()))))\n\u001b[1;32m     91\u001b[0m \u001b[39m# Compute the ratio\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (4,) and (20,20) not aligned: 4 (dim 0) != 20 (dim 0)"
     ]
    }
   ],
   "source": [
    "estimateur.grad_ML_RR(theta_star=theta_true, n_simulations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
