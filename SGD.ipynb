{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import Code\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:orange\">  **Cadre général de la descente de gradient stochastique pour obtenir une estimation du maximum de vraisemblance**  </span>\n",
    "\n",
    "On se donne un échantillon d'observations $\\boldsymbol{x} \\in \\mathbb{R}^{20} = [x^{(1)}, ..., x^{(20)}]^T$ tiré selon une loi paramétrée par $\\theta$, qui est donc le paramètre du modèle probabiliste que nous souhaitons estimer. La log-vraisemblance des données observées $\\ell (\\theta) = \\log p_{\\theta}(\\boldsymbol{x}) = \\sum_{i=1}^{20} \\log p_{\\theta}(x^{(i)})$ est maximisée pour obtenir une estimation de maximum de vraisemblance (EMV) du paramètre $\\theta$. \n",
    "\n",
    "En utilisant la **descente de gradient stochastique (SGD)**, l'algorithme pour estimer les paramètres peut être formulé comme suit :\n",
    "\n",
    "\n",
    "1. **Initialisation** : On choisit un $\\theta^{(0)}$ De manière aléatoire ou déterministe. On peut par exemple choisir une telle valeur à partir d'une première approximation.\n",
    "\n",
    "2. **Itération** : À chaque itération $t$, les paramètres $\\theta$ sont mis à jour en utilisant un échantillon aléatoire de données $x^{(i)}$ (donc pour $i \\in \\{1, ..., 20\\}$) tiré de l'ensemble de données et on a alors : \n",
    "\\begin{equation}\n",
    "\\theta^{(t+1)} = \\theta^{(t)} - \\eta \\nabla_{\\theta} \\log p_{\\theta^{(t)}}(x^{(i)}),\n",
    "\\end{equation}\n",
    "\n",
    "    où $\\eta$ est le **taux d'apprentissage** (également appelé pas d'apprentissage) et $\\nabla_{\\theta} \\log p_{\\theta^{(t)}}(\\boldsymbol{x}^{(i)})$ est le gradient du logarithme de la vraisemblance conditionnelle évalué pour l'échantillon $\\boldsymbol{x}^{(i)}$ à l'itération $t$. \n",
    "\n",
    "3. **Convergence** : On répète $(1)$ jusqu'à ce qu'un critère d'arrêt prédéfini soit satisfait. Par exemple, on peut fixer pour un $\\epsilon$ donné le critère d'arrêt suivant :  \n",
    "$$ \n",
    "\\| \\theta^{(t+1)} - \\theta^{(t)} \\| < \\epsilon\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:violet\">  1.1. **Calcul explicite du gradient de la log-vraisemblance**  </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans l'article, pour effectuer l'expérience empirique, on nous donne la valeur explicite de la densité avec laquelle on tire les observations $\\boldsymbol{x}$. On nous donne : \n",
    "\n",
    "$$\n",
    "p_{\\theta}(\\boldsymbol{x}) = \\mathcal{N}(\\boldsymbol{x}|\\theta \\mathbf{1}_{20}, 2\\mathbf{I}_{20}) = \\frac{1}{(4\\pi)^{10}} \\exp \\left\\{ -\\frac{1}{4} (\\boldsymbol{x} - \\theta \\mathbf{1}_{20})^T  (\\boldsymbol{x} - \\theta \\mathbf{1}_{20}) \\right\\}\n",
    "$$\n",
    "\n",
    "Ainsi, on a : \n",
    "\n",
    "$$\n",
    "\\log p_{\\theta}(\\boldsymbol{x}) = \\sum_{i=1}^{20}  \\log p_{\\theta}(x^{(i)}) = \\sum_{i=1}^{20} \\log \\left( \\frac{1}{2\\sqrt{\\pi}} \\exp\\left(-\\frac{(x - \\theta)^2}{4}\\right) \\right)\n",
    "$$\n",
    "\n",
    "Une fois cette expression explicite de la log-vraisemblance obtenue, on peut calculer explicitement le gradient de celle-ci **par rapport au paramètre  $\\theta$**. On a : \n",
    "\n",
    "$$\n",
    "\\nabla_{\\theta} \\log p_{\\theta} (\\boldsymbol{x}) = \\sum_{i=1}^{20}  \\log \\nabla_{\\theta} p_{\\theta}(x^{(i)}) = \\frac{1}{2} \\sum_{i=1}^{20} (x^{(i)} - \\theta)\n",
    "$$\n",
    "\n",
    "Si bien que l'on retrouve la version du gradient **en un point** de l'échantillon $\\boldsymbol{x}$ que l'on utilise dans l'étape itérative : \n",
    "\n",
    "$$\n",
    "\\nabla_{\\theta} \\log p_{\\theta}(x^{(i)}) = \\frac{1}{2} (x^{(i)} - \\theta)\n",
    "$$\n",
    "\n",
    "A MODIFIER + ERREUR D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:violet\">  1.2. **Tirage du paramètre génératif $\\theta$**  </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant toute chose, on tire une valeur du paramètre $\\theta$ que l'on considère comme étant la quantité que l'on souhaite approximer dans la suite de cette partie. On sait d'après le cadre de l'application numérique de l'article que $\\theta \\sim \\mathcal{N}(1, 0)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La valeur de theta à estimer est 1.196656338822547\n"
     ]
    }
   ],
   "source": [
    "#theta_true = np.random.multivariate_normal(np.zeros(20), np.identity(20))\n",
    "theta_true = np.random.normal(0, 1)\n",
    "print(f\"La valeur de theta à estimer est {theta_true}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:violet\">  1.3. **Tirage de l'échantillon**  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'échantillon d'observation x de taille 20 sur lequel on travaillera tiré est \n",
      " \n",
      " [0.24443130832021476, -0.7473378469232477, 4.4329166658149335, 1.169916783842436, 0.7137881470861469, 2.1369494640017646, -0.43180564350280415, 1.8978805340238074, 0.0015435555260405742, -0.8311578203428838, -0.7476618139539877, 0.18778114691734316, 0.15883649026641655, -0.8574109906498679, -0.5471480408128437, 1.1005532262958666, 1.5777580201228363, 1.9228123473298226, 0.31994220090781134, 1.8224328307755984]\n"
     ]
    }
   ],
   "source": [
    "def p_theta_x(theta_val):\n",
    "    \n",
    "    x = []\n",
    "\n",
    "    for _ in range(20):\n",
    "        x.append(np.random.normal(loc=theta_val, scale=np.sqrt(2)))\n",
    "\n",
    "    return x\n",
    "\n",
    "true_x = p_theta_x(theta_true)\n",
    "\n",
    "print(f\"L'échantillon d'observation x de taille 20 sur lequel on travaillera tiré est \\n \\n {true_x}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:violet\">  1.4. **Adaptation de l'itération avec des estimation du gradient**  </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " l'idée est désormais d'adapter l'étape itérative décrite précédemment. Dans le cas où celle-ci est mise à jour à partir d'une estimation du gradient. On notera $\\hat{\\nabla}^{\\text{SUMO}}_{\\theta}, \\hat{\\nabla}^{\\text{ML-SS}}_{\\theta}, \\hat{\\nabla}^{\\text{ML-RR}}_{\\theta}$ et $\\hat{\\nabla}^{\\text{IWAE}}_{\\theta}$ l'estimateur du gradient selon les quatre méthodes sur lesquels repose nous travail (SUMO, ML_SS, ML_RR et IWAE).\n",
    "\n",
    "**Itération** : Par exemple, en utilisant l'estimateur du gradient avec la méthode SUMO, on a l'itération $t$ du paramètres $\\theta$ donnée, en utilisant un échantillon aléatoire de données $x^{(i)}$ (donc pour $i \\in \\{1, ..., 20\\}$) tiré de l'ensemble de données : \n",
    "\\begin{equation}\n",
    "\\theta^{(t+1)} = \\theta^{(t)} - \\eta \\hat{\\nabla}^{\\text{SUMO}}_{\\theta} (x^{(i)}),\n",
    "\\end{equation} \n",
    "\n",
    "A MODIFIER (?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:violet\">  1.4. **Étape itérative avec des estimation du gradient**  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD_iteration(theta_t, true_x, eta, r, k_IWAE, n_simulations, method):\n",
    "\n",
    "    ## on tire un indice entre 0 et 19 (inclus)\n",
    "    random_index = random.randint(0, 19)\n",
    "\n",
    "    ## On crée un vecteur de taille 20 dont tous les éléments sont nuls, sauf celui donnée par l'index random_index\n",
    "    modified_x = np.zeros(20)\n",
    "    modified_x[random_index] = true_x[random_index]\n",
    "\n",
    "    ## on recalcule noised_A et noised_b SELON LE PARAMÈTRE PRÉCÉDENT theta_t\n",
    "    A, b = np.eye(20), (theta_t/2)*np.ones(20)\n",
    "    noised_A, noised_b = Code.noised_params(A, b)\n",
    "\n",
    "    if method == 'IWAE':\n",
    "        ## on calcule le gradient selon l'estimateur donné dans method\n",
    "        grad_theta_t = Code.grad_IWAE(modified_x, noised_A, noised_b, theta_t, k_IWAE, n_simulations)\n",
    "\n",
    "    elif method == 'SUMO':\n",
    "        ## on calcule le gradient selon l'estimateur donné dans method\n",
    "        grad_theta_t = Code.grad_SUMO(r, modified_x, noised_A, noised_b, theta_t, n_simulations)\n",
    "\n",
    "    elif method == 'ML_SS':\n",
    "        ## on calcule le gradient selon l'estimateur donné dans method\n",
    "        grad_theta_t = Code.grad_IWAE(r, modified_x, noised_A, noised_b, theta_t, n_simulations)\n",
    "\n",
    "    elif method == 'ML_RR':\n",
    "        ## on calcule le gradient selon l'estimateur donné dans method\n",
    "        grad_theta_t = Code.grad_IWAE(r, modified_x, noised_A, noised_b, theta_t, n_simulations)\n",
    "\n",
    "    theta_next =  theta_t - eta * grad_theta_t\n",
    "\n",
    "    return theta_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD_iteration_tom(true_x, sum_log, position, theta_t, eta, r, k_IWAE, n_simulations, method):\n",
    "\n",
    "    modified_x = true_x[position]\n",
    "\n",
    "    ## on recalcule noised_A et noised_b SELON LE PARAMÈTRE PRÉCÉDENT theta_t\n",
    "    #A, b = np.eye(20), (theta_t/2)*np.ones(20)\n",
    "    #noised_A, noised_b = Code.noised_params(A, b)\n",
    "    \n",
    "    A, b = np.eye(2), (theta_t/2)*np.ones(2)\n",
    "    noised_A, noised_b = Code.noised_params(A, b, dim=2)\n",
    "\n",
    "    if method == 'IWAE':\n",
    "        ## on calcule le gradient selon l'estimateur donné dans method\n",
    "        grad_theta_t = Code.grad_IWAE(modified_x, noised_A, noised_b, float(theta_t), k_IWAE, n_simulations, dim = 2, one_shot=True)\n",
    "\n",
    "    elif method == 'SUMO':\n",
    "        ## on calcule le gradient selon l'estimateur donné dans method\n",
    "        grad_theta_t = Code.grad_SUMO(r, modified_x, noised_A, noised_b, float(theta_t), n_simulations, dim = 2, one_shot=True)\n",
    "\n",
    "    elif method == 'ML_SS':\n",
    "        ## on calcule le gradient selon l'estimateur donné dans method\n",
    "        grad_theta_t = Code.grad_ML_SS(r, modified_x, noised_A, noised_b, float(theta_t), n_simulations, dim = 2, one_shot=True)\n",
    "\n",
    "    elif method == 'ML_RR':\n",
    "        ## on calcule le gradient selon l'estimateur donné dans method\n",
    "        grad_theta_t = Code.grad_ML_RR(r, modified_x, noised_A, noised_b, float(theta_t), n_simulations, dim = 2, one_shot=True)\n",
    "\n",
    "     ## On prend le ième terme de notre somme et cela sera celui-ci que l'on dérive à cette itération\n",
    "    sum_log[position] = grad_theta_t\n",
    "\n",
    "    theta_next =  theta_t + eta * sum(sum_log)/len(sum_log) ## ON est sur du gradient ascent\n",
    "\n",
    "    return theta_next, sum_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois le code pour les itération fini, on s'attaque à la convergence de l'algorithme de descendre de gradient stochastique rien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD_convergence(theta_0, true_x, eps, eta, r, k_IWAE, n_simulations, method):\n",
    "    \n",
    "    ## On initialise la somme des log pour chaque i\n",
    "    sum_log = []\n",
    "\n",
    "    if method == 'IWAE':\n",
    "        \n",
    "        #for i in range(10):\n",
    "            #sum_log.append(Code.grad_IWAE(true_x[i, i+1], np.eye(20), (theta_0/2)*np.ones(20), theta_0, k_IWAE, n_simulations, dim = 2, one_shot=True, range=1))\n",
    "        for i in range(len(true_x)) : \n",
    "            sum_log.append(Code.grad_IWAE(true_x[i], np.eye(2), (theta_0/2)*np.ones(2), theta_0, k_IWAE, n_simulations, dim = 2, one_shot=True, range=1))\n",
    "\n",
    "    elif method == 'SUMO':\n",
    "\n",
    "        for i in range(len(true_x)) : \n",
    "            sum_log.append(Code.grad_SUMO(r, true_x[i], np.eye(2), (theta_0/2)*np.ones(2), theta_0, n_simulations, dim = 2, one_shot=True, range=1))\n",
    "\n",
    "    elif method == 'ML_SS':\n",
    "\n",
    "        for i in range(len(true_x)) : \n",
    "            sum_log.append(Code.grad_ML_SS(r, true_x[i], np.eye(2), (theta_0/2)*np.ones(2), theta_0, n_simulations, dim = 2, one_shot=True, range=1))\n",
    "    \n",
    "    elif method == 'ML_RR':\n",
    "\n",
    "        for i in range(len(true_x)) : \n",
    "            sum_log.append(Code.grad_ML_RR(r, true_x[i], np.eye(2), (theta_0/2)*np.ones(2), theta_0, n_simulations, dim = 2, one_shot=True, range=1))\n",
    "\n",
    "    print(f\" voici la sommelog {sum_log}\")\n",
    "\n",
    "    theta_t = [0, theta_0]\n",
    "    theta_t.append(SGD_iteration_tom(true_x, sum_log, 0, theta_0, eta, r, k_IWAE, n_simulations, method))\n",
    "    t = 1\n",
    "    while abs(theta_t[t] - theta_t[t-1]) > eps:\n",
    "        \n",
    "        ## peut-être que l'on peut inverser les deux boucles cela ferait plus de sens mais c'est pour voir si ça s'arrête\n",
    "\n",
    "        for i in range(len(true_x)):\n",
    "            print(f'thetaT{theta_t[t]}')\n",
    "            theta_next, sum_log = SGD_iteration_tom(true_x, sum_log, i, theta_t[t], eta, r, k_IWAE, n_simulations, method)\n",
    "            print(f\"thetaNext{theta_next}\")\n",
    "            if abs(theta_next - theta_t[t]) < eps:\n",
    "                return theta_next\n",
    "            else : \n",
    "                theta_t.append(theta_next)\n",
    "                t += 1\n",
    "\n",
    "    return theta_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " voici la sommelog [-5.75457732930621, 5.772747263647018, 15.522527109391852, -2.603962372863295, 3.003192456817807, -5.454291864323864, 42.33409176213, -10.777794122339312, 0.3932377173867003, 0.17082934817887718, 1.0369226839993653, 1.243086706067274, 20.76511524944371, 16.15446377933097, -3.6238853217579514, -5.761693592626701, -5.316396013628726, -14.969086225049251, -14.77236572236361, -93.19062863507806]\n",
      "-3\n",
      "thetaT-3\n",
      "-3\n",
      "thetaNext-3.323375828584384\n",
      "thetaT(-3.19352961106633, [-14.601275923239635, 5.772747263647018, 15.522527109391852, -2.603962372863295, 3.003192456817807, -5.454291864323864, 42.33409176213, -10.777794122339312, 0.3932377173867003, 0.17082934817887718, 1.0369226839993653, 1.243086706067274, 20.76511524944371, 16.15446377933097, -3.6238853217579514, -5.761693592626701, -5.316396013628726, -14.969086225049251, -14.77236572236361, -93.19062863507806])\n",
      "(-3.19352961106633, [-14.601275923239635, 5.772747263647018, 15.522527109391852, -2.603962372863295, 3.003192456817807, -5.454291864323864, 42.33409176213, -10.777794122339312, 0.3932377173867003, 0.17082934817887718, 1.0369226839993653, 1.243086706067274, 20.76511524944371, 16.15446377933097, -3.6238853217579514, -5.761693592626701, -5.316396013628726, -14.969086225049251, -14.77236572236361, -93.19062863507806])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'tuple' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sg/lxw89kss0x727nlhml9vq0nm0000gn/T/ipykernel_93237/1626431068.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ML_RR'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mSGD_conv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGD_convergence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_IWAE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_simulations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/sg/lxw89kss0x727nlhml9vq0nm0000gn/T/ipykernel_93237/942097779.py\u001b[0m in \u001b[0;36mSGD_convergence\u001b[0;34m(theta_0, true_x, eps, eta, r, k_IWAE, n_simulations, method)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'thetaT{theta_t[t]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mtheta_next\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGD_iteration_tom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_IWAE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_simulations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"thetaNext{theta_next}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta_next\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtheta_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/sg/lxw89kss0x727nlhml9vq0nm0000gn/T/ipykernel_93237/844183964.py\u001b[0m in \u001b[0;36mSGD_iteration_tom\u001b[0;34m(true_x, sum_log, position, theta_t, eta, r, k_IWAE, n_simulations, method)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#noised_A, noised_b = Code.noised_params(A, b)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtheta_t\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mnoised_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoised_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoised_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'tuple' and 'int'"
     ]
    }
   ],
   "source": [
    "theta_0 = -3\n",
    "#eta = 0.0001\n",
    "#eps = 0.001\n",
    "eta = 0.1\n",
    "eps = 0.05\n",
    "r = 0.6\n",
    "k_IWAE = 5\n",
    "n_simulations = 5 \n",
    "method = 'ML_RR'\n",
    "\n",
    "SGD_conv = SGD_convergence(theta_0, true_x, eps, eta, r, k_IWAE, n_simulations, method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_convergence(convergence_values, theta_true):\n",
    "    \"\"\"\n",
    "    Trace la convergence des points vers la valeur du vrai paramètre.\n",
    "\n",
    "    Args:\n",
    "    - convergence_values (list or numpy array): Liste des valeurs de convergence de l'algorithme.\n",
    "    - theta_true (float): Valeur vraie du paramètre.\n",
    "\n",
    "    \"\"\"\n",
    "    num_iterations = len(convergence_values)\n",
    "    iterations = np.arange(1, num_iterations + 1)  # Numéro des itérations\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(iterations, convergence_values, color='blue', label='Convergence')\n",
    "    plt.axhline(y=theta_true, color='red', linestyle='--', label='True Parameter Value')\n",
    "\n",
    "    plt.title('Convergence vers la valeur du vrai paramètre')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Valeur de convergence')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'numpy.float64' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sg/lxw89kss0x727nlhml9vq0nm0000gn/T/ipykernel_93237/1157918723.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_convergence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSGD_conv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/sg/lxw89kss0x727nlhml9vq0nm0000gn/T/ipykernel_93237/878282343.py\u001b[0m in \u001b[0;36mplot_convergence\u001b[0;34m(convergence_values, theta_true)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \"\"\"\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mnum_iterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvergence_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0miterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iterations\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Numéro des itérations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'numpy.float64' has no len()"
     ]
    }
   ],
   "source": [
    "plot_convergence(SGD_conv, theta_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La descente de gradient stochastique (SGD) est un algorithme d'optimisation largement utilisé pour estimer les paramètres d'un modèle probabiliste par maximum de vraisemblance. L'algorithme fonctionne de la manière suivante :\n",
    "\n",
    "1. Choisir un point initial $ \\theta_0 $ dans l'espace des paramètres.\n",
    "2. Itération jusqu'à convergence :\n",
    "2.1. Échantillonnage stochastique : Sélectionner aléatoirement un échantillon $(x_i, y_i)$ parmi les données d'entraînement.\n",
    "2.2. Calcul du gradient : Calculer le gradient de la fonction de perte par rapport aux paramètres du modèle en utilisant l'échantillon sélectionné : $ \\nabla_{\\theta} \\mathcal{L}(\\theta; x_i, y_i) $.\n",
    "2.3. Mise à jour des paramètres : Mettre à jour les paramètres du modèle en utilisant le gradient calculé et un taux d'apprentissage $ \\eta $ : $ \\theta_{t+1} = \\theta_t - \\eta \\nabla_{\\theta} \\mathcal{L}(\\theta_t; x_i, y_i) $.\n",
    "\n",
    "\n",
    "\\textbf{Remarques :}\n",
    "\\begin{itemize}\n",
    "    \\item Le terme \"stochastique\" vient du fait que le gradient est calculé sur un seul échantillon à la fois, ce qui rend l'algorithme adapté aux grands ensembles de données.\n",
    "    \\item Le choix du taux d'apprentissage \\( \\eta \\) est crucial ; un taux d'apprentissage trop grand peut entraîner des oscillations et une convergence instable, tandis qu'un taux d'apprentissage trop petit peut ralentir la convergence.\n",
    "    \\item La convergence de l'algorithme dépend de plusieurs facteurs, notamment du choix du taux d'apprentissage, de la fonction de perte utilisée et de la nature de l'ensemble de données.\n",
    "\\end{itemize}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
